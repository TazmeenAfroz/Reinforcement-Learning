# Reinforcement Learning Course â€“ Spring 2025 ðŸŽ“

Welcome to the official GitHub repository for the **Reinforcement Learning** course at FAST NUCES, Spring 2025.  
This repo contains links, notes, and material related to the lecture series.

ðŸ“º **YouTube Playlist**:  
[Watch all lectures here](https://youtube.com/playlist?list=PLjZUumCUD_XwTTzVRK8TSwI_RsvBDZraC&si=sdaEeyAA6synccm-)

---

## ðŸ§  Topics Covered

Below is a list of all **topics** covered in this course:

- Introduction to Reinforcement Learning (RL)
- Types of Learning: Induction vs Deduction
- Types of Machine Learning
- Agent, Environment, Rewards, Actions, States, Policy, Goal
- Multi-Armed Bandit Problem
- Expected Value and Action-Value Methods
- Sample Average & Incremental Update
- Exploration vs Exploitation
- Epsilon-Greedy Algorithm
- Optimistic Initial Values
- Upper Confidence Bound (UCB)
- Markov Decision Processes (MDPs)
- Markov Property
- Deterministic vs Stochastic Policies
- Return and Discounted Rewards
- Episodic vs Continuous Tasks
- Bellman's Equation
- Value of a State and State-Action
- Optimal Policies
- Bellman's Optimality Equations
- Dynamic Programming
- Policy Evaluation & Iteration
- Value Iteration
- Model-Based vs Model-Free Methods
- Monte Carlo (MC) Methods
- MC Prediction & Control
- Exploring Starts
- Epsilon-Soft Policies
- Off-Policy vs On-Policy Methods
- Importance Sampling
- Temporal Difference (TD) Learning
- SARSA Algorithm
- Q-Learning
- Q-Planning
- Dyna Architecture & Dyna-Q
- Dyna-Q+
- Choosing the Right Algorithm
- Value Function Approximation
- Objective & Loss Functions in RL
- Monte Carlo Gradient Method
- TD Semi-Gradient Method
- Deep Q-Learning (CartPole Example)
- Policy Gradient & Gradient Ascent
- REINFORCE Algorithm

---

## ðŸ“… Course Duration

- **Start Date:** January 27, 2025  
- **End Date:** May 8, 2025  
- Weekly sessions, quizzes, assignments, sessionals, and class activities included.

---

## ðŸ“Œ Note

This repository is managed by a student for academic purposes.  

Feel free to fork, star, and contribute if you're taking the course or revising RL!

